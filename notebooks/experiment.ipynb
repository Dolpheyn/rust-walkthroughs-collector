{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv openai langchain faiss-cpu langchain-community ollama chromadb\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%reload_ext dotenv\n",
    "\n",
    "if 'OPENAI_API_KEY' not in os.environ: print('`OPENAI_API_KEY` environment variable is missing.')\n",
    "if 'OPENAI_API_BASE_URL' not in os.environ: print('`OPENAI_API_BASE_URL` environment variable is missing.')\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "OPENAI_API_BASE_URL = os.environ.get(\"OPENAI_API_BASE_URL\")\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "def get_client(base_url=OPENAI_API_BASE_URL, api_key=OPENAI_API_KEY):\n",
    "    client = AzureOpenAI(\n",
    "        api_key=api_key,\n",
    "        api_version=\"2023-03-15-preview\",\n",
    "        base_url=base_url\n",
    "    )\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./output/contents/https-blog-burntsushi-net-transducers'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "files = glob.glob('./output/contents/*')\n",
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_files = []\n",
    "for filepath in files:\n",
    "    content = '\\n'.join([\n",
    "        line.strip()\n",
    "        for line\n",
    "            in open(filepath, 'r').read().strip().split('\\n')\n",
    "        if len(line.strip())\n",
    "    ])\n",
    "    filename = filepath.split('/')[-1]\n",
    "    scraped_files.append((filename, content))\n",
    "\n",
    "len(scraped_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 1,600,000,000 Keys with Automata and Rust - Andrew Gallant's Blog\n",
      "It turns out that finite sta\n"
     ]
    }
   ],
   "source": [
    "print(scraped_files[0][1][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CLEANED_DIR = './output/contents'\n",
    "def try_get_cleaned_content(fname):\n",
    "    fpath = os.path.join(CLEANED_DIR, fname)\n",
    "    if not os.path.exists(fpath):\n",
    "        return None\n",
    "    return open(fpath, 'r').read()\n",
    "\n",
    "EMBEDDINGS_DIR = \"./output/embeddings\"\n",
    "def store_embeddings(fname, embeddings):\n",
    "    fpath = os.path.join(EMBEDDINGS_DIR, fname)\n",
    "    import json\n",
    "    open(fpath, 'w').write(json.dumps(embeddings))\n",
    "\n",
    "def get_embedding(text, client, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "import ollama\n",
    "def get_embedding_ollama(text, model=\"mxbai-embed-large\"):\n",
    "    return ollama.embeddings(\n",
    "        model=model,\n",
    "        prompt=text,\n",
    "    )\n",
    "\n",
    "def split_text_into_chunks(text):\n",
    "    from langchain.text_splitter import CharacterTextSplitter\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator='\\n',\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "import chromadb\n",
    "def get_chromadb_client():\n",
    "    return chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromadb_client = get_chromadb_client()\n",
    "chromadb_collection = None\n",
    "collection_name = 'rust-walkthrough-articles'\n",
    "try:\n",
    "    chromadb_collection = chromadb_client.create_collection(collection_name)\n",
    "except:\n",
    "    chromadb_collection = chromadb_client.get_collection(collection_name)\n",
    "\n",
    "# embeddings - generate and store\n",
    "for (fname, content) in scraped_files[:10]:\n",
    "    maybe_cleaned_content = try_get_cleaned_content(fname)\n",
    "    if maybe_cleaned_content is None:\n",
    "        continue\n",
    "    content = maybe_cleaned_content\n",
    "    text_chunks = split_text_into_chunks(content)\n",
    "    chunked_embeddings = [(fname, i, get_embedding_ollama(chunk)['embedding']) for (i, chunk) in enumerate(text_chunks)]\n",
    "    chromadb_collection.add(\n",
    "        ids=[f\"{fname}-{i}\" for (fname, i, _) in chunked_embeddings],\n",
    "        embeddings=[embedding for (_, _, embedding) in chunked_embeddings],\n",
    "        documents = text_chunks,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['http-laurocaetano-com-programming-2021-01-23-raft-leader-election-rust-0',\n",
       "   'http-laurocaetano-com-programming-2021-01-23-raft-leader-election-rust-4',\n",
       "   'https-blog-tarkalabs-com-how-to-build-a-web-application-using-rust-part-iii-ed6511ebaa97-1',\n",
       "   'http-laurocaetano-com-programming-2021-01-23-raft-leader-election-rust-1',\n",
       "   'https-www-diegofreijo-com-blog-rlox-vm-a-lox-interpreter-in-rust-part-1-11',\n",
       "   'https-konghq-com-blog-writing-an-ebpf-xdp-load-balancer-in-rust-22',\n",
       "   'http-laurocaetano-com-programming-2021-01-23-raft-leader-election-rust-7',\n",
       "   'https-konghq-com-blog-writing-an-ebpf-xdp-load-balancer-in-rust-5',\n",
       "   'https-konghq-com-blog-writing-an-ebpf-xdp-load-balancer-in-rust-6',\n",
       "   'https-onevariable-com-blog-phase-locked-state-machines-2']],\n",
       " 'distances': [[221.2075958251953,\n",
       "   226.83206176757812,\n",
       "   230.14593505859375,\n",
       "   230.21128845214844,\n",
       "   230.98770141601562,\n",
       "   235.8857879638672,\n",
       "   238.7687530517578,\n",
       "   240.87452697753906,\n",
       "   241.87466430664062,\n",
       "   243.11216735839844]],\n",
       " 'metadatas': [[None, None, None, None, None, None, None, None, None, None]],\n",
       " 'embeddings': None,\n",
       " 'documents': [[\"Implementing Raft's Leader Election in Rust – Lauro Caetano\\nConsensus algorithms is a topic that always caught my attention: it is complex and hard and needs a precise and safe solution. In other words: We have a couple of machines forming a cluster, and they operate on identical copies of the same data and can continue operating even in the scenario of some servers being down. This approach is used to solve a bunch of problems in distributed systems.\\nTo give a bit of background of where we currently stand, we have to talk about Paxos. Over the past decade or more, Paxos was almost synonymous with consensus, as it is the protocol taught in most computer science courses, and most implementations of consensus make use of it. The only problem is that Paxos is really difficult to understand, thus making it very hard to be implemented correctly. With that, Diego Ongaro and John Ousterhout designed Raft, with the most important goal of making it understandable.\",\n",
       "   'This is a very simplistic and short explanation for the leader election process, and for more details do not hesitate in reading the paper! It’s a very pleasant read.\\nRust is a programming language designed for performance, safety, and safe concurrency. It is strongly typed, compiled, has no garbage collector, and has no runtime (a.k.a a very minimal runtime).\\nI got interested in Rust at the end of 2020, by reading a couple of blog posts. With that trigger, I decided to read The Rust Programming Language book and started to code very small projects. Only that very small projects do not tell you much about the language in the real world. So I decided to implement something that is more related to what I work on on my daily basis: dealing with distributed systems.\\nNote: if you are not familiar with the language, you can quickly check the Gentle intro to Rust.',\n",
       "   'You can find the video here :\\nYou can find the source code I am building in this series over at github. Here’s the database manager module along with how we’re using it.\\nThe DB::Manager module usestokio::mpscchannel under the hood and allows us to asynchronously query for data. We make use of message passing to represent different database actions we want to perform, such as, getting all or single or creating, updating or deleting UrlMap data. We embed a tokio::oneshot channel within this message which the manager uses to send back the results of the action to the caller.\\nWe usetokio::mpsc channel to allow multiple queries to be run simultaneously, typically this would happen when such queries are run from within multiple http request handlers serving multiple users. This allows us to scale our database manager linearly over all the cores of the CPU for maximum efficiency.\\nIn Part III of this series, you’ll learn how to leverage tokio asynchronous runtime for Rust to do the following:',\n",
       "   'Given that Raft focuses so much on understandability, it breaks down the consensus into three relatively independent subproblems (quoting the Raft paper):\\nLeader election: a new leader must be chosen when an existing leader fails.\\n  Log replication: the leader must accept log entries from clients and replicate them across the cluster, forcing the other logs to agree with their own\\n  Safety: if any server has applied a given log entry to its state machine, then no other server may apply a different command for the same log index.\\nIn this blog post, I will cover only the Leader election. The other two topics I will cover in the future in other blog posts!\\nA Raft cluster is composed of several servers and five is a typical number, therefore allowing the system to have two failures. A server in this cluster is in one of three possible states:\\nLeader: Handles all client requests.\\n  Followers: are passive, and only respond to requests from leaders.',\n",
       "   'When I read Virtual Machine I used to think about a very complex piece of software. It turns out the one I implemented ended up being pretty simple. And short, compared to the Compiler.\\nThe main VM method, run, is a loop that keeps matching for the current Operation. Once it knows what operation it should run, it just executes it using Rust’s code. Nothing too fancy.\\nThe book proposes two different ways to implement variables, depending on if they are a global variable (defined outside of a function) or a local one (defined in a function, including parameters).\\nFor the globals, it implements a map data structure implemented over a trie. A pretty interesting implementation. On my end, instead, I just went with a simple Rust hash map. For the locals, they are pushed on the stack for faster access.',\n",
       "   \"That's it! Well, almost. For full source and further reading check out https://github.com/shaneutt/ebpf-rust-udp-loadbalancer-demo.\\nIncrease developer productivity, security, and performance at scale with the unified platform for API management, service mesh, and ingress controller.\\nSign up for Kong newsletter\\nTerms•Privacy•Trust and Compliance\\n© Kong Inc. 2024\",\n",
       "   'With that, we have covered all the steps for the state transitions in Raft’s leader election algorithm!\\nThe core logic for the leader election is implemented in the raft::core package, where functions to handle log entries (heartbeats), elections, and timeouts are placed. Please visit the full implementation for a more detailed look into the code.\\nImportant notes\\nRPCs are done through TCP connections. Each server starts up with a TPC listener, and create client connections to all other servers in the cluster.\\nThe implementation is not making usage of persistent storage, so all operations are done in memory. For this reason, the Server instance is shared across many functions, by making usage of Rust’s Arc and Mutex combination. It took me a while to understand the concepts, but once you get the basics, it turns out very simple!\\nThere is a demo, which runs and demonstrates the process of electing a leader in a new cluster. By running it, we get the following output:',\n",
       "   \"CompanyAbout UsCareersPress RoomInvestorsContact UsPartnerKong Partner ProgramEventsAPI Summit by KongUpcoming EventsSupportEnterprise Support PortalProfessional ServicesDocumentationSecurityTrust and Compliance\\nLoginGet a DemoStart for Free\\nEngineeringEnterpriseLearning CenterKong NewsProduct Releases\\nExplore TopicsAPI GatewayService MeshInsomniaKubernetesAPI SecurityAI Gateway\\nAPI GatewayService MeshInsomniaKubernetesAPI SecurityAI Gateway\\nHomeBlogEngineeringWriting an eBPF/XDP load-balancer in Rust\\nIn today's cloud ecosystem the demands for high functioning and high performance observability, security and networking functionality for applications and their network traffic are as high as ever.\",\n",
       "   \"In today's cloud ecosystem the demands for high functioning and high performance observability, security and networking functionality for applications and their network traffic are as high as ever.\\nHistorically a great deal of this kind of functionality has been implemented in userspace, but the ability to program these kinds of things directly into the operating system can be very beneficial to performance. The operating system has been a very challenging place to dynamically add functionality in the past, often requiring the development and management of very cumbersome kernel modules, but in recent years eBPF has become a burgeoning technology in the Linux Kernel which is changing all that.\",\n",
       "   'A state machine for the host - usually pushing the client through each step\\nA \"wire protocol\", for the actual kinds of message and the sequence of messages sent to achieve all the state transitions\\nThis means I write three chunks of software in three places, and if I change any one part, I need to make sure the other two are consistent.\\nYes, I know I\\'m writing three things. But that is frustrating, because I\\'m not writing three things: I\\'m writing one thing that exists in three places:\\nOn the client\\nOn the host\\nOver the wire\\nI run into problems that are roughly this shape, but I haven\\'t been able to find a good way of specifying directly in code.\\nOften I end up drawing the sequence up on paper.\\nFor state machines, this means drawing state machine diagrams, one for the client and one for the host. A client diagram could look like this:']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents', 'distances']}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = get_embedding_ollama('distributed systems')['embedding']\n",
    "chromadb_collection.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response = get_client().chat.completions.create(\n",
    "#  model=\"gpt-35-turbo\", # replace this value with the deployment name you chose when you deployed the associated model.\n",
    "#  messages = [{\n",
    "#      \"role\": \"system\",\n",
    "#      \"content\": \"\"\n",
    "#  },\n",
    "#  {\n",
    "#      \"role\": \"user\",\n",
    "#      \"content\": \"\",\n",
    "#  }],\n",
    "#  temperature=2,\n",
    "#  top_p=0.95,\n",
    "#  frequency_penalty=0,\n",
    "#  presence_penalty=0,\n",
    "#  stop=None)\n",
    "#\n",
    "#print(response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
